{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 1115390\n",
      "\n",
      "\n",
      "\n",
      "First 100 characters:\n",
      "\n",
      "['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n', 'B', 'e', 'f', 'o', 'r', 'e', ' ', 'w', 'e', ' ', 'p', 'r', 'o', 'c', 'e', 'e', 'd', ' ', 'a', 'n', 'y', ' ', 'f', 'u', 'r', 't', 'h', 'e', 'r', ',', ' ', 'h', 'e', 'a', 'r', ' ', 'm', 'e', ' ', 's', 'p', 'e', 'a', 'k', '.', '\\n', '\\n', 'A', 'l', 'l', ':', '\\n', 'S', 'p', 'e', 'a', 'k', ',', ' ', 's', 'p', 'e', 'a', 'k', '.', '\\n', '\\n', 'F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't', 'i', 'z', 'e', 'n', ':', '\\n', 'Y', 'o', 'u']\n"
     ]
    }
   ],
   "source": [
    "#List of all possible characters\n",
    "CHARS = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\" \\\n",
    "        + \"!\\\"#$%&\\'()*+,-./:;â€”<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c\"\n",
    "\n",
    "#Will contain raw characters from the corpus\n",
    "corpus = []\n",
    "with open('shakespeare.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        for char in line.strip():\n",
    "            corpus.append(char)\n",
    "        corpus.append('\\n')\n",
    "\n",
    "print(\"Total number of characters:\", len(corpus))\n",
    "print(\"\\n\\n\")\n",
    "print(\"First 100 characters:\\n\")\n",
    "print(corpus[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of distinct chars: 101\n"
     ]
    }
   ],
   "source": [
    "#Map from character to its corresponding index\n",
    "char2idx = {char : i for i, char in enumerate(CHARS)}\n",
    "#Map from index to its corresponding character\n",
    "idx2char = {i : char for i, char in enumerate(CHARS)}\n",
    "\n",
    "NUM_CHARS = len(char2idx)\n",
    "print(\"Total number of distinct chars:\", NUM_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus with indices:\n",
      "[41, 18, 27, 28, 29, 95, 38, 18, 29, 18, 35, 14, 23, 77, 97, 37, 14, 15, 24, 27, 14, 95, 32, 14, 95, 25, 27, 24, 12, 14, 14, 13, 95, 10, 23, 34, 95, 15, 30, 27, 29, 17, 14, 27, 73, 95, 17, 14, 10, 27, 95, 22, 14, 95, 28, 25, 14, 10, 20, 75, 97, 97, 36, 21, 21, 77, 97, 54, 25, 14, 10, 20, 73, 95, 28, 25, 14, 10, 20, 75, 97, 97, 41, 18, 27, 28, 29, 95, 38, 18, 29, 18, 35, 14, 23, 77, 97, 60, 24, 30]\n",
      "\n",
      "Size of dataset: 2000\n"
     ]
    }
   ],
   "source": [
    "#Corpus but with indices as opposed to characters\n",
    "corpus_with_indices = [char2idx[char] for char in corpus]\n",
    "\n",
    "print(\"Corpus with indices:\")\n",
    "print(corpus_with_indices[:100])\n",
    "\n",
    "SIZE_OF_SNIPPET = 250\n",
    "#Dataset will contain 2000 random 250 character blocks from corpus\n",
    "dataset = []\n",
    "for _ in range(2000):\n",
    "    \n",
    "    snipped_start = np.random.randint(0, len(corpus_with_indices) - SIZE_OF_SNIPPET)\n",
    "    snipped = corpus_with_indices[snipped_start:snipped_start + SIZE_OF_SNIPPET]\n",
    "    \n",
    "    dataset.append((\n",
    "        torch.LongTensor(snipped[:-1]),\n",
    "        torch.LongTensor(snipped[1:])\n",
    "    ))\n",
    "\n",
    "print(\"\\nSize of dataset:\", len(dataset))\n",
    "\n",
    "X = torch.stack([xy[0] for xy in dataset])\n",
    "Y = torch.stack([xy[1] for xy in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model\n",
    "class ShakespeareGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        #Size of embedding used to represent characters\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        #Size of hidden and cell state within LSTM\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        #Embedding module: Maps character indices to dense vector representations\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=NUM_CHARS,\n",
    "            embedding_dim=self.embedding_size\n",
    "        )\n",
    "        \n",
    "        #LSTM module to be used for character generation\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_size,\n",
    "            hidden_size=self.hidden_size\n",
    "        )\n",
    "        \n",
    "        #Linear mapping to be used to go from LSTM outputs to character predictions\n",
    "        self.linear = nn.Linear(\n",
    "            in_features=self.hidden_size,\n",
    "            out_features=NUM_CHARS\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, batched_inputs):\n",
    "        #Number of character blocks to be considered simultaneously\n",
    "        batch_size = batched_inputs.shape[1]\n",
    "        #Hidden and Cell state initialized to all ones\n",
    "        h, c = self.get_initial_hc(batch_size)\n",
    "        #Character block length\n",
    "        seq_len = batched_inputs.shape[0]\n",
    "\n",
    "        #Embeddings from raw character inputs\n",
    "        embeddings = self.embedding(batched_inputs)\n",
    "        \n",
    "        #Outputs and final state of LSTM after processing embedddings\n",
    "        outputs, (h, c) = self.lstm(\n",
    "                embeddings.reshape(seq_len, batch_size, self.embedding_size),\n",
    "                (h, c)\n",
    "        )\n",
    "        \n",
    "        #Use linear mapping to map LSTM outputs to character predictions\n",
    "        outputs = self.linear(torch.squeeze(outputs))\n",
    "\n",
    "        #Return outputs and final state\n",
    "        return outputs, (h, c)\n",
    "\n",
    "\n",
    "    def get_initial_hc(self, batch_size):\n",
    "\n",
    "        return (torch.zeros(1, batch_size, self.hidden_size),\n",
    "                torch.zeros(1, batch_size, self.hidden_size))\n",
    "\n",
    "\n",
    "    def generate(self, initial_token=' ', num_tokens=100, temperature=1):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            #Index of current character initialized to initial character\n",
    "            token = torch.LongTensor([char2idx[initial_token]])\n",
    "            #state of LSTM initialized to all ones\n",
    "            h, c = self.get_initial_hc(1)\n",
    "            #To contain predicted characters in a list\n",
    "            chars = []\n",
    "            \n",
    "            for _ in range(num_tokens):\n",
    "                \n",
    "                #Add current character to list\n",
    "                chars.append(idx2char[token.item()])\n",
    "                \n",
    "                #Use embedding of current character as input\n",
    "                inp = self.embedding(token)\n",
    "                \n",
    "                #Pass current embedding through LSTM and get output and new state\n",
    "                out, (h, c) = self.lstm(inp.reshape(1, 1, self.embedding_size), (h, c))\n",
    "                \n",
    "                #Distribution of possible character predictions based on output\n",
    "                dist = self.linear(out.reshape(1, -1))\n",
    "                \n",
    "                #Temperature controls variation of distribution.  High temperature implies\n",
    "                #likely characters are made more likely.  Low temperature increases chances\n",
    "                #of less likely characters\n",
    "                dist = dist.data.view(-1).div(temperature).exp()\n",
    "                \n",
    "                #Sample character from distribution\n",
    "                chosen_i = torch.multinomial(dist, 1)[0]\n",
    "                \n",
    "                #Update current character\n",
    "                token = torch.LongTensor([chosen_i])\n",
    "                \n",
    "            #Join elements of list into single string    \n",
    "            return ''.join(chars[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training of this model takes a long time\n",
    "#For Demo we will used pretrained weights\n",
    "EPOCHS = 500\n",
    "LR = 0.1\n",
    "BETA = 0.8\n",
    "EMBEDDING_SIZE = 100\n",
    "HIDDEN_SIZE = 64\n",
    "\n",
    "USE_PRETRAINED = True\n",
    "\n",
    "net = ShakespeareGenerator(EMBEDDING_SIZE, HIDDEN_SIZE).float()\n",
    "\n",
    "#Softmax Cross Entropy Loss used \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=BETA)\n",
    "\n",
    "if USE_PRETRAINED:\n",
    "    net.load_state_dict(torch.load('shakespeare.pt', map_location=lambda storage, loc: storage))\n",
    "    \n",
    "else:\n",
    "    for _ in range(EPOCHS):\n",
    "\n",
    "        output, _ = net(X.transpose(0, 1))\n",
    "        output = output.transpose(0, 1)\n",
    "\n",
    "        loss = criterion(output.reshape(-1, NUM_CHARS), Y.reshape(-1))\n",
    "\n",
    "        print(loss.item())\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man, wrom sound reak, he shall I cake madne to my Duke thou hy his Goo to wale dogy,\n",
      "Munde-negit, wirs;\n",
      "And thou hove him\n",
      "afte beth which\n",
      "Thy his hand.\n",
      "\n",
      "BALT:\n",
      "Prance\n",
      "maging to he! thenrous the cast a-Sarse thou bow had I wall as thousalagint, come in thy not your falselvy must is wecomfulfer-fair, and the bonuter pore,\n",
      "Have, roth bain'd him of kneet these, the hope I are wesince with be where I can young becion lime, now you, mild a chupinden some cphering is, one mit have no gear the decover a mid, I? I usty meble\n",
      "Beast,\n",
      "For will west the hound? and the moisposainge.\n",
      "\n",
      "BAd God he mack thou term.\n",
      "\n",
      "PAT:\n",
      "O clomeo give an\n",
      "Am will an, my good boxssout ing betnon,\n",
      "One us my can:\n",
      "I know pore the fear, yeper, 'twery\n",
      "Sheek.\n",
      "I the face streinged Jeast:\n",
      "fold thou stressethe, promile;\n",
      "For Critnine.\n",
      "\n",
      "Offer third, my Trance with. Habious the caitia medawt thy maly, what napen a decord, he binds fet rave to shot be all one blowsts.\n",
      "\n",
      "ESCUS:\n",
      "Be body be we allion-\n",
      "\n",
      "HENRY:\n",
      "You my lolw hily bem oinders, \n"
     ]
    }
   ],
   "source": [
    "#Temperature=1 Probability Distribution used as predicted.\n",
    "print(net.generate(temperature=1, num_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jo;\n",
      "No never ifold Not nybxe. Thight;\n",
      "This otumpebictleit I yar nave-ckequncy',\n",
      "Eronourkehen hazes\n",
      "abshey: rurrackial!\n",
      "As thurrity of art.\n",
      "\n",
      "Artly.\n",
      "Lord Monou, Pom\n",
      "him, can.\n",
      "\n",
      "Alr, naf for not-bases; preseds woul.\n",
      "TRISTER:\n",
      "Weldidnoth thince kintuse!\n",
      "You tonguenett.\n",
      "What, Corriet\n",
      "once. pences liding\n",
      "ifory we, deas@our abiouss by jewey. Whatle, to by\n",
      "Ond,\n",
      "whats forry drlalf\n",
      "\n",
      "Mabookies.\n",
      "\n",
      "ROMEO:\n",
      "Stlive abuix. Aws.\n",
      "So con.\n",
      "Save.\n",
      "\n",
      "RGEON:\n",
      "Comass'd. Didged. Triure?\n",
      "\n",
      "LORMAMILLATES:\n",
      "Bemaisfoor-be me:\n",
      "'Tis at my we,\n",
      "Or fantink.\n",
      "Byo, go oift\n",
      "Townely, feeptain.\n",
      "Now? Alde-abuide-CLIFF::\n",
      "Nay, nacles' is\n",
      "UMustaid nights, slismiss'd.\n",
      "No?\n",
      "\n",
      "DUKEUTHafforecemanmore, your apt are; I shus, have a geverent my m, for' titdreeh I went; for sea,\n",
      "Cites in sabs's don, agredw'd a be tor,\n",
      "As--o coombgorssif;\n",
      "To<ybift\n",
      "Assizbey! yo's oaft\n",
      "To del.\n",
      "Your Das times,\n",
      "Wifery a shery\n",
      "And toople kither qusteicipeden,\n",
      "word?\n",
      "Good gour,\n",
      "Ermbisde\n",
      "Let stoglear I mewoulaits, bey allin gnoted, deign\n",
      "Thou ibron; thy shy, ingear your L\n"
     ]
    }
   ],
   "source": [
    "#Temperature=1.5 more likely characters are used more often\n",
    "print(net.generate(temperature=1.5, num_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the lords, the dangerth the shall shall the are the so man the live the sea the so man the some man the sea the devery come the for the sea the death the so the so man the man and the lords with the see the sea the death here the man the so sons of the hath you the shall the so so father the seen the seem and the so sound the proclain and the so the sea the so the so for the come the live the say the come the pardemen the perent of the parding the son the live and the shall the his deast the so should shall the see the lord the love the do the singer the sea the so parder a so shall the deal the desure with the man the heart a prove a man the death the death the so be the live it the so so man to hear a some strept:\n",
      "And the proclain the destill the shall not the so the shall the seen the so be and the heart you him the present the seemence the man the dead the lay the be my countrether the words make the so man the father to the seement the shall the countress and the lords, the count\n"
     ]
    }
   ],
   "source": [
    "#Temperature=0.25 Less likely characters are used more often.\n",
    "print(net.generate(temperature=0.25, num_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
